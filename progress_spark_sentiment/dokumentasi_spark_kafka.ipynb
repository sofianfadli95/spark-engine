{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codingan utk membaca data Streaming dari Kafka menggunakan Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import library utk kita membuat direktori tmpt kita menyimpan data\n",
    "import os\n",
    "# Disini library os jg dpt kita manfaatkan utk mendownload\n",
    "# file jar yg kita perlukan pada saat kita menjalankan Pyspark\n",
    "# Apabila file jar belum tersedia, maka akan didownload otomatis\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'\n",
    "# Kemudian, utk mengakses masalah I / O file, kita membutuhkan library io\n",
    "import io\n",
    "# Library utk men-load maupun men-dump data berformat JSON\n",
    "import json\n",
    "# Library utk meng-import fungsi delay\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan meng-import library dari Pyspark yg kita perlukan. Perlu diperhatikan bahwa Apache Spark telah terinstall di komputer yang ingin kita jalankan. Setelah itu, pastikan pula bahwa library pyspark telah terinstall di versi Python yg kita gunakan. Install pyspark dgn cara mengetikkan \"pip install pyspark\" pada command prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    Spark\n",
    "from pyspark import SparkContext  \n",
    "#    Spark Streaming\n",
    "from pyspark.streaming import StreamingContext  \n",
    "#    Kafka\n",
    "from pyspark.streaming.kafka import KafkaUtils  \n",
    "#    json parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita perlu mengimpor library eksternal Python yang bernama Sastrawi. Sastrawi berfungsi utk men-stemming atau mendapatkan kata dasar dari suatu kata. Contohnya : menyentuh -> sentuh, membunuh -> bunuh, dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inisialisasi fungsi Stemmer bahasa Indonesia\n",
    "# Stemmer untuk membuang semua imbuhan dan mendapatkan kata dasarnya\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita perlu mengimpor dictionary lookup. Dictionary lookup ini berfungsi utk mengubah bentuk kata-kata alay menjadi kata bentuk formalnya. Contoh : gw -> saya, egp -> memang saya pikirin, sotoy -> sok tahu. Untuk meng-enrich kata-kata yang baru, kalian dapat menambahkannya sendiri di file formalizationDict.txt. (Perlu diperhatikan bahwa antara kata alay dan kata perbaikannya dipisahkan menggunakan tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {}\n",
    "# Dictionary utk lemmatize\n",
    "with io.open(\"formalizationDict.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        items = line.split()\n",
    "        key, values = items[0], items[1:]\n",
    "        lookup_dict[key] = ' '.join(values)\n",
    "\n",
    "# Fungsi untuk menimpa kata-kata yang salah / alay dengan kata\n",
    "# yang terdapat pada formalizationDict\n",
    "# Contoh : gpp => tidak apa-apa\n",
    "#          egp => emang saya pikirin\n",
    "        \n",
    "def _lookup_words(input_text):\n",
    "    words = input_text.split() \n",
    "    new_words = []\n",
    "    new_text = \"\"\n",
    "    for word in words:\n",
    "        if word.lower() in lookup_dict:\n",
    "            word = lookup_dict[word.lower()]\n",
    "        new_words.append(word)\n",
    "        new_text = \" \".join(new_words) \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita perlu membuat fungsi standar untuk cleansing text dari tanda baca dan symbol dari text. Kita dapat menggunakan fungsi library re (regular expression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \" \", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
